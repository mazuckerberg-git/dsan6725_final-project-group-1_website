---
title: "Tools"
format:
  html:
    toc: true
    embed-resources: true
---

## Programming Languages and Frameworks

The primary programming language used in our project is Python, which is widely used in the data science and machine learning communities. We utilized several libraries and frameworks to build our application, but the most notable ones are:

- **LangChain**: This is the main framework we used to build our multi-agent system. It provides a modular and flexible architecture for creating and managing agents, as well as tools for data retrieval and processing. LangChain's [documentation](https://python.langchain.com/docs/) provides detailed information on how to use its various components.

- **Streamlit**: This is a Python library that allows us to create interactive web applications. We used Streamlit to build the user interface for our application, which acts as a chat interface for users to interact with our agents. The [Streamlit documentation](https://streamlit.io/) provides information on how to use its features and components.

## Cloud Platforms

Using the skills we obtained in this course, we used AWS as our cloud platform to deploy our application. Additionally, we used Amazon Bedrock to access the LLMs and Amazon SageMaker for model training and deployment.

For the structure and creation of our agents, we used LangChain and its various modules as the framework for our multi-agent system. To create and store our data that the agents access, we used FAISS (Facebook AI Similarity Search) as our vector database. This allows us to store and retrieve data efficiently, as well as append new data to the vectorstore if requested by the user. 

Lastly, to create our user interface, we used Streamlit, a Python library that allows us to create interactive web applications. Our streamlit app acts as a chat interface, allowing users to interact with our agents and receive real-time insights on stock market data.

### Data Gathering Tools
The tools we defined for our data gathering agent are the following: `data_gathering()`, `data_to_vectorstore()`. The first tool is responsible for gathering data from the user's query. The data gathering process includes several logics to ensure that the data gathered is the most recent based on the existing baseline data. The second tool is responsible for storing the data in the vector knowledge base. These tools are defined via the LangChain tools module including Hugging Face Embeddings and FAISS indexes. These tools, which are further described on the [Data page](2_data.html), are called upon through the data gathering agent via its defined system prompt.

### RAG Tools

As mentioned previously, we used LangChain to create our RAG agent. This agent is responsible for retrieving relevant data from our vector database and generating responses to user queries. Again, since we are using a rag chain to retrieve and answer user queries, we do not have any tools defined for this agent.

### Data Engineering Tools

The tools we defined for our data engineering agent are the following: `code_generation()`, `code_execution()`, and `documentation()`. These tools are defined via the LangChain tools module. These tools, which are further described on the [Agents page](4_agents.html), are called upon through the engineering agent via its defined system prompt.

## User Interface
By using Streamlit to create our user interface, we were able to create an interactive web application that its easy to use and to customize for our expectations. The Streamlit app acts as a chat interface. After the user enters their query, the agents are initialized and the multi-agent system is executed. We leverage of the queue output system to be able to provide the user with dynamic status updates on the progress of the agents. The final output is then displayed and saved in the chat history. We use the `st.markdown` module to format the output and make it more attractive and readable. When the response generated includes visualizations, we use the streamlit `st.image` to display the image in the chat interface. A video demo of the interface is available on the [Video Demo](11_video.html) page.

## Version Control and CI/CD

For version control, we used Git and hosted our code on GitHub. Our Github repository contains all the code for our pipeline, as well as milestone documents, working files from previous iterations, and a README file that provides an overview of the project. We also used several branches in our repository to manage different features and iterations of our project. 


<br>
<!-- Reference to next section -->
<div style="text-align: right; font-size: 14px;">
  <a href="7_evaluations.html">Next Section: Evaluation of Effectiveness</a>
</div>

---

### References:

${^1}$ [LangChain](https://python.langchain.com/docs/)

${^2}$ [Bedrock](https://www.bedrock.aws/)

${^3}$ [Streamlit](https://streamlit.io/)

${^4}$ [Github](https://docs.github.com/en/get-started/using-git/about-git)
