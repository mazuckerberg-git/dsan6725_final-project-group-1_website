---
title: "Responsible AI Considerations"
format:
  html:
    toc: true
    embed-resources: true
---

## Bias and Fairness

To ensure that our Stock Market LLM Assistant is fair and unbiased, and most importantly, avoided hallucinations, we mainly focused on the following aspects:

1. **LLM Temperature**: We set the temperature of our LLM to 0.2, which is a low value that helps to reduce the randomness of the model's output. This means that the model is less likely to generate unexpected or irrelevant responses, which can help to reduce bias and improve the overall quality of the generated text. This is particularly important in the context of stock market analysis, where accuracy to the data extracted and reliability are crucial.

2. **RAG Hallucination Reduction**: During the first iteration of our RAG agent, we noticed the model was generating hallucinations, which are false or misleading information. To address this issue, we first appended filterable data to the "metadata" portion of our json structure prior to storing it in the vectorstore. This metadata includes the datetime of the stock data, the name of the ticker, and the source if it was price data or news data. Additionally, we also changed our embedding model to `intfloat/e5-small-v2` to improve the RAG agent's ability to retrieve relevant data. Lastly, we increased the retriever k value to 30 to ensure that the model retrieves the most relevant data from the vectorstore to answer the user's query. These improvements resulted in an agent that provides more accurate information and reduces the risk of hallucinations.

3. **Using Publicly Available Data**: We used publicly available data from Yahoo Finance and Finnhub as our knowledge base. This data is widely used in the finance industry and is considered to be reliable and accurate. By using this data, we can ensure that our model is not biased towards any specific source or dataset.

4. **Manual Review of Outputs**: We conducted a manual review of the outputs generated by our model to ensure that they are accurate and unbiased. This involved checking the outputs against the original data and ensuring that they are consistent with the user's query. 

5. **Notice to Users**: We included a notice to users that the model is only for educational purposes and statistical analysis. We wanted to ensure that users understand the limitations of the model and that they should not rely solely on its outputs for making investment decisions. The notice we provide is listed below:

> **Notice**: This report provides code generated, explanations of key decisions made by the LLM system, and the resulting outputs and insights. All insights are derived from statistical and time series analysis. Any financial decisions made based on this information are solely at the discretion of the user. The assistant does not constitute financial advice and should not be relied on for investment decisions.


Thus, we have taken several steps to ensure that our Stock Market LLM Assistant is fair and unbiased. By focusing on the temperature of the LLM, reducing hallucinations in the RAG agent, using publicly available data, conducting manual reviews of outputs, and providing a notice to users, we can ensure that our model is reliable and accurate while acknowledging its limitations.


<br>
<!-- Reference to next section -->
<div style="text-align: right; font-size: 14px;">
  <a href="9_findings.html">Next Section: Findings and Insights</a>
</div>

