[
  {
    "objectID": "8_AI_considerations.html",
    "href": "8_AI_considerations.html",
    "title": "Responsible AI Considerations",
    "section": "",
    "text": "Bias and fairness checks conducted.\nAny measures taken to reduce hallucinations and ensure factual consistency.\nPrivacy considerations (e.g., PII removal, data anonymization).\nModel safety measures and ethical implications.\n\n \n\nNext Section: Findings and Insights\n\n\n\nReferences:\n\\({^1}\\)"
  },
  {
    "objectID": "9_findings.html",
    "href": "9_findings.html",
    "title": "Findings and Insights",
    "section": "",
    "text": "Key takeaways from the project.\nUnexpected challenges and how they were addressed.\nPerformance trade-offs and scalability considerations. –&gt; In Conclusion\n\n \n\nNext Section: Conclusion and Future Work\n\n\n\nReferences:\n\\({^1}\\)"
  },
  {
    "objectID": "7_evaluations.html",
    "href": "7_evaluations.html",
    "title": "Evaluation of Effectiveness",
    "section": "",
    "text": "Metrics used for evaluation (e.g., BLEU, ROUGE, MRR, Precision/Recall for retrieval, perplexity for LLMs).\nBenchmarking comparisons against baselines.\nUser studies, feedback, or qualitative assessments."
  },
  {
    "objectID": "7_evaluations.html#ragas-evaluations",
    "href": "7_evaluations.html#ragas-evaluations",
    "title": "Evaluation of Effectiveness",
    "section": "Ragas Evaluations",
    "text": "Ragas Evaluations"
  },
  {
    "objectID": "7_evaluations.html#user-feedback",
    "href": "7_evaluations.html#user-feedback",
    "title": "Evaluation of Effectiveness",
    "section": "User Feedback",
    "text": "User Feedback\n \n\nNext Section: Responsible AI Considerations\n\n\n\nReferences:\n\\({^1}\\) Ragas"
  },
  {
    "objectID": "2_data.html",
    "href": "2_data.html",
    "title": "Data Sources",
    "section": "",
    "text": "For our Stock Market LLM Assistant project we selected data sources that directly align with the requirements of financial analysis and stock market insight generation. As the project focuses on stock market evaluation, our primary data source is stock price information from Yahoo Finance. This data is crucial for understanding price fluctuations, identifying trends, comparing performance of different stocks and enabling robust statistical analysis.\nTo complement price data and provide users with deeper insights, we also included news data from the recent news section associated with each ticker on Yahoo Finance. This allows the Assistant justify its answers and produce more informed, complete financial evaluations.\nWe gather ticker prices by scraping Yahoo Finance using the requests package in Python to retrieve detailed information such as Trading Date, Open Price, High Price, Low Price, Close Price, Company Name, among others.\nFor the news data, we use the Finnhub Stock API, as well-structured, highly regarded financial API built around REST principles. Using an API key, we extract company news within a specified date range and collect information such as Headline, Source, Summary, and URL."
  },
  {
    "objectID": "2_data.html#data-preparation",
    "href": "2_data.html#data-preparation",
    "title": "Data Sources",
    "section": "Data Preparation",
    "text": "Data Preparation\nSince the price data is collected through web scraping, it was essential to perform several cleaning and transformation steps to ensure data quality and consistency. Some of the primary preprocessing tasks included converting fields from integer formats to proper datetime objects, and ensuring that all price-related fields were stored as numeric types. To facilitate better filtering and organization, we also augmented the data by adding key metadata, such as the ticker name, the month and year extracted from the trading date, and a source label indicating whether the entry corresponded to price or news data.\nFor the news data obtained through the Finnhub API, the information was already structured and relatively clean. The main transformation involved converting the timestamp field from an integer format into a datetime object.\nThese preprocessing and augmentation steps are applied consistently across all tickers, ensuring a uniform structure. Finally, all processed data is saved both locally and in Amazon S3 buckets in JSON format, optimized for future loading into FAISS vector stores for efficient retrieval.\n \n\nNext Section: Retrieval-Augmented Generation (RAG)\n\n\n\nReferences:\n\\({^1}\\) Finnhub-API\n\\({^2}\\) Yahoo Finance"
  },
  {
    "objectID": "10_conclusion.html",
    "href": "10_conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "Summary of the project and its impact."
  },
  {
    "objectID": "10_conclusion.html#limitations",
    "href": "10_conclusion.html#limitations",
    "title": "Conclusion",
    "section": "Limitations",
    "text": "Limitations\n\nLimitations of the current implementation."
  },
  {
    "objectID": "10_conclusion.html#future-improvememnents",
    "href": "10_conclusion.html#future-improvememnents",
    "title": "Conclusion",
    "section": "Future Improvememnents",
    "text": "Future Improvememnents\n\nPotential future improvements and extensions."
  },
  {
    "objectID": "6_tools.html",
    "href": "6_tools.html",
    "title": "Tools",
    "section": "",
    "text": "Programming languages and frameworks used (e.g., Python, PyTorch, TensorFlow, Hugging Face, OpenAI API).\nCloud platforms and any relevant services (e.g., Amazon Bedrock, Amazon SageMaker, Vector DBs like FAISS), open-source (e.g. LangChain).\nVersion control, CI/CD, or deployment considerations.\nMention Langchain for all agents\nMention Bedrock for invoking the models\nFAISS mentioned in models?\nVersion control was done using Git"
  },
  {
    "objectID": "6_tools.html#frameworks",
    "href": "6_tools.html#frameworks",
    "title": "Tools",
    "section": "Frameworks",
    "text": "Frameworks\nMention streamlit interface with in chat loggers\n \n\nNext Section: “Evaluation of Effectiveness\n\n\n\nReferences:\n\\({^1}\\) LangChain\n\\({^2}\\) Bedrock\n\\({^3}\\) Streamlit\n\\({^4}\\) [Github] (https://docs.github.com/en/get-started/using-git/about-git)"
  },
  {
    "objectID": "3_rag.html",
    "href": "3_rag.html",
    "title": "Retrieval-Augmented Generation (RAG)",
    "section": "",
    "text": "Within our multi-agent pipeline, we have implemented a Retrieval-Augmented Generation (RAG) system to act as the question-answering portion of the application. The RAG system is designed to read the user’s query, retrieve the sources needed in the vectorstore to answer the question, and consolidate the sources to provide an accurate answer. This is especially important for stock market data, as the information is constantly changing, includes exact values, and is often time-sensitive. With a RAG we’re able to avoid any type of hallucination and provide the most accurate and up-to-date information to the user.\nThe RAG system is built using the LangChain framework, which allows us to easily integrate various components such as the vectorstore, retriever, and LLM. The vectorstore was created using FAISS, a popular library for efficient similarity search and clustering of dense vectors. The embeddings used to create the vectorstore were generated from Hugging Face’s intfloat/e5-small-v2 model, which is lightweight and efficient with both semantic understanding and numeric retrieval capabilities. Our retriever is uses the maximum marginal relevance (MMR) algorithm to ensure that the retrieved documents are both relevant and diverse, which is crucial for providing comprehensive answers to user queries. Additionally, we have set k in the retriever to 30 since we found the RAG to suffer in retrieving the correct documents when k was lower, mainly due to the fact the RAG struggles with filtering data by specific dates and names. Lastly, the LLM used for answer generation is Claude 3.5 Sonnet from Anthropic, which is a state-of-the-art model known for its reasoning capabilities and ability to generate coherent and contextually relevant responses with being too wordy.\nWhen it came to creating the structure of the RAG, we also need to take into consideration the chat history and how to best utilize it. We decided that rather than creating a RAG chain, we would seperate it by question answer chain and document retrieval. We first combine the user query and the chat history into a single string, which is then passed to the retriever to find the most relevant documents. The retrieved documents are then passed to the question answer chain, (made up of the llm, system prompt, and documents) to generate a response. This approach allows us to maintain the context of the conversation while ensuring that the RAG system can effectively retrieve and utilize the most relevant information.\nThe RAG system is able to provide a cohesive answer, either directly based on the retrived documents or a statement that not enough data was found, back to the supervisor agent to be sent to the user. The system is build such that the supervisor agent simple transfers the RAG’s output to the user instead of augmenting any additonal details to avoid any type of hallucination.\n \n\nNext Section: AI Agents\n\n\n\nReferences:\n\\({^1}\\) LangChain\n\\({^2}\\) Hugging Face\n\\({^3}\\) FAISS"
  },
  {
    "objectID": "1_introduction.html",
    "href": "1_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Our Stock Market LLM Assistant will be designed to provide insights on stock market data using a multi-agent system. The application leverages data engineering and RAG (Retrieval-Augmented Generation) agents to automate data collection, processing, and query handling. The data agent gathers stock market data via APIs, and cleans and stores it using FAISS. The engineering agent generates visualizations, executes code, and documents processes. The RAG agent answers user queries, analyzes stock trends, compares tickers, and generates customized datasets and visualizations. Our fully-functioning generative AI model will be contained in a user-friendly application which offers an interactive and intuitive experience for users seeking stock market insights.\nOur goal for this assistant is to create an application that is accessible to a wide range of users; from novice investors to experienced traders. The streamlit interface acts like a chat bot that allows users to ask questions about stock market data and receive real-time insights. Automated report generation, especially in finance, is a powerful and needed tool in the corporate world right now and we believe this project to serve as a stepping stone into more sophisticated iterations in the future for others to build upon."
  },
  {
    "objectID": "1_introduction.html#points-of-analysis",
    "href": "1_introduction.html#points-of-analysis",
    "title": "Introduction",
    "section": "Points of Analysis",
    "text": "Points of Analysis\n\nData Science Question\n\nHow can we build a Stock Market LLM Assistant leveraging multi-agent systems to deliver users with an efficient, intuitive interface for comprehensive financial and technical stock market analysis?\n\n\n\nProject Questions:\n\nWhat sources of data are the most relevant to provide users with accurate and timely stock market insights?\n\n\nCan we create a multi-agent system that automates data collection, processing, and query handling for stock market analysis?\n\n\nWhat models and techniques can we implement for RAG to optimize query-to-context retrieval and response generation?\n\n\nCan we implement tools that allow users to generate customized financial reports and visualizations?\n\n\nShould we consider AI ethics and bias in our model to ensure uninformed decision-making?\n\n\nWhat are future improvements we can make to enhance the performance and usability of the Stock Market LLM Assistant?\n\n \n\nNext Section: Data Sources and Preparation\n\n\n\n\nReferences:\n\\({^1}\\) Gamage, P. (2026). Applied Time Series for Data Science."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Speeding up Stock Market Insights with Generative AI",
    "section": "",
    "text": "M.S. in Data Science and Analytics\n    \n\n    Applied Generative AI for Developers\n    Final Project\n    Speeding up Stock Market Insights with Generative AI\n    A Multi-Agent System for Stock Market Analysis\n    By: Shriya Chinthak and Maria Agustina Zuckerberg"
  },
  {
    "objectID": "4_agents.html",
    "href": "4_agents.html",
    "title": "AI Agents",
    "section": "",
    "text": "Architecture of AI agents used.\nFrameworks used (e.g., LangChain, LlamaIndex, Haystack).\nTypes of agents (e.g., tool-using agents, autonomous agents, planning agents).\nHow agents interact with external tools and APIs.\nExplain overall structure, graph and in memory"
  },
  {
    "objectID": "4_agents.html#supervisor-agent",
    "href": "4_agents.html#supervisor-agent",
    "title": "AI Agents",
    "section": "Supervisor Agent",
    "text": "Supervisor Agent"
  },
  {
    "objectID": "4_agents.html#data-gathering-agent",
    "href": "4_agents.html#data-gathering-agent",
    "title": "AI Agents",
    "section": "Data Gathering Agent",
    "text": "Data Gathering Agent"
  },
  {
    "objectID": "4_agents.html#rag-agent",
    "href": "4_agents.html#rag-agent",
    "title": "AI Agents",
    "section": "RAG Agent",
    "text": "RAG Agent"
  },
  {
    "objectID": "4_agents.html#data-engineering-agent",
    "href": "4_agents.html#data-engineering-agent",
    "title": "AI Agents",
    "section": "Data Engineering Agent",
    "text": "Data Engineering Agent\n \n\nNext Section: Models and Technologies Used\n\n\n\nReferences:\n\\({^1}\\)"
  },
  {
    "objectID": "5_model.html",
    "href": "5_model.html",
    "title": "Models",
    "section": "",
    "text": "Discussion on the models utilized (LLMs, embedding models, classifiers, etc.).\nComparison of different models and justification for final choices.\nAny inference optimizations applied (e.g., quantization, distillation, multi-adapter swapping).\nMention FAISS embeddings for tabular data\nMention Claude for code and answer generation"
  },
  {
    "objectID": "5_model.html#technologies-used",
    "href": "5_model.html#technologies-used",
    "title": "Models",
    "section": "Technologies Used",
    "text": "Technologies Used\n \n\nNext Section: Tools and Frameworks\n\n\n\nReferences:\n\\({^1}\\) LangChain\n\\({^2}\\) Hugging Face\n\\({^3}\\) Bedrock\n\\({^4}\\) FAISS"
  }
]